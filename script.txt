슬라이드1
안면인식 기반 단골관리 시스템을 구현한 10조 또왔슈입니다. 발표 시작하겠습니다

슬라이드2
AI에서는 딥러닝기반 안면인식모텔을 구현했고 안면인식 Rest API개발을 하였습니다
클라우드에서는 아키텍처 설계와 데이터 베이스 구축을 담당했고 빅데이터는 요기요 웹크롤링과
행렬분해를 활용한 추천시스템을 구현했습니다.
아이오티에서는 안드로이드기반 얼굴인식 기능 구현을 담당하였습니다.

슬라이드3
프로젝트 수행도구는 다음과 같습니다

슬라이드4
목차는 다음과 같고 

슬라이드5
아키텍처는 다음과 같습니다(간단한 설명..?)

슬라이드6
다음과 같은 일정으로 진행하였습니다.

슬라이드7
또왔슈의 기획의도는 

슬라이드8
요즘 사회는 개인 맞춤형 컨텐츠를 제공하는 서비스를 많이 이용하며
얼마전 메뉴이름에 단골손님의 이름을 넣은 짐승파스타처럼 단골서비스에대한 관심도 많이 생겨나고 있습니다

슬라이드9
그리하여 저희는 언택트와 개인화, 그리고 단골서비스를 모두합친 시스템을 구현하도록 계획했고
또왔슈라는 서비스를 만들게 되었습니다.

슬라이드 11
 요기요 웹 사이트를 통해 ID, 주만 날짜, 주문 메뉴, 평점, 코멘트 데이터를 수집합니다.

슬라이드12
 실제 요기요에 등록된 리뷰들을 csv파일로 저장 한 모습입니다.

슬라이드 13
 크롤링 데이터를 바탕으로 메인메뉴와 사이드메뉴를 그룹으로 나눠 각각 추천 할 수
있도록 해주고 빅데이터에서는 다차원 행렬을 SVD와 같은 차원감소기법을 이용해 분해를
해주고 잠재요인을 찾아내는 행렬분해기법을 사용했습니다.

슬라이드14
행렬분해로 진행하는 협업필터링은 사용자와 아이템의 행렬데이터를 이용해
잠재요인을 찾아 예측해줍니다.
즉, 사용자와 아이템의 행렬을 사용자와 잠재요인, 아이템과 잠재요인행렬로 
분해할 수 있습니다.

슬라이드15
즉 저희가 사용한 행렬분해 방식은 사용자가 평가하지 않은 메뉴의 평점을 
0리 예측해 추천해주는 방식이고 행렬분해 방식은 중간에 잠재요인을 뽑아내기때문에 
저장공간을 절약할 수 있다는 장점이 있습니다. 현재는 데이터의 수가 많지않지만
방대한 데이터를 사용할 경우 행렬분해 방식이 일단 협업필터링방식보다 효과적일 것입니다

슬라이드 16
IoT에서는 안드로이드 구현을 진행했습니다.
Retrofit을 이용하여 Rest API로 데이터를 전송하고 
고객 회원가입, 사진촬영 데이터를 서버로 POST방식으로 전달하게 됩니다

슬라이드 17
어플 실행을 해서 신규버튼을 클릭하면 신규 회원 데이터를 입력할 수 있는 페이지가 나옵니다.
회원정보를 기입하고 입력을 누르면 AI 서버 DB로 전송이 됩니다.
카메라 아이콘을 누르면 신규회원의 사진을 찍을 수 있는 사진촬영기능과 
그 사진을 AI 서버로 업로드할 수 있는 사진전송 기능이 있습니다.
데이터 전송을 완료하게 되면 서버에서 회원정보와 사진이 함께 저장이 됩니다.
단골버튼을 누르면 사진촬영 동의를 받은 후 단골손님의 사진을 찍어서 AI서버로 보내면
안면인식 기능을 통해 그 사진과 일치하는 사진의 회원정보를 리턴해줍니다.
받은 회원정보를 통해 빅데이터 서비스를 연동해 그 고객에 맞는 추천 메뉴판을 볼 수 있습니다.
따라서 하단에 일반메뉴를 누르면 일반메뉴판을,
단골메뉴를 누르면 단골손님전용메뉴판을 보실 수가 있습니다.(줄여도 될듯합니다)

슬라이드 18
AI는 다음과 같은 Process를 통해 모델을 구축하였습니다.
간단히 설명드리면 AIHub의 한국인 이미지 데이터를 통해 데이터 수집 및 모델링에 필요한 이미지를 선별하였고, 
OpenCv와 Dlib라이브러리를 활용하여 이미지를 전처리했습니다.
이후 Inception모델과 앵귤러 마진 손실함수를 기반으로 이미지 특징벡터를 128차원으로 임베딩하여 거리기반으로 
얼굴 이미지간 유사도를 측정할 수 있는 모델을 구현했습니다. 
다음슬라이드에서 좀 더 자세하게 설명드리도록 하겠습니다.

슬라이드19
우선 데이터는 보시는 것처럼 400명의 고유 인물을 다양한 카메라 각도, 조명 각도, 액세사리 착용 여부, 
표정으로 구분하여 수집된 데이터로 총 4,320,000개의 고화질 이미지입니다. 
일반적으로 기존에 구현되어 있는 서양인의 데이터로 구현된 안면인식 모델을 이용할 경우 동양인과 
잘 안맞을 수 있다는 점에서 AIhub에서 이와 같은 한국인 안면 이미지 데이터를 수집했습니다.

슬라이드20
다음으로 너무 각도가 많이 벗어난 옆모습 또는 위에서 찍은 이미지의 경우에는 안면 인식과 거리가 멀어 제외하였고, 
안경을 제외한 악세사리의 경우 안면인식과 크게 관련성이 없어 제외하여 총 모델 구축용 720,000개의 이미지를 선별하였습니다.

슬라이드21
이미지 전처리의 경우에는 객체 추출에는 OpenCV를 활용하여 이미지속에서 얼굴 부분만 추출하였고, 
이중에서도 얼굴의 특징과 위치를 잘 표현할 수 있는 랜드마크를 검출하여 모델링에 사용하기 위해 Dlib라이브러리를 활용했습니다. 보시는것과 같이 
이미지속에서 68개의 얼굴 특징 벡터를 찾아내는 것을 알 수 있습니다.

슬라이드22
이렇게 추출한 랜드마크를 Inception모델의 아키텍처를 기반으로 68개의 벡터값을 최종적으로 128차원으로 임베딩하는 모델을 구현했습니다. 

슬라이드23
특히 손실함수의 경우 앵귤러 마진 거리 기반 손실함수를 이용했는데, 소프트맥스 함수의 경우 충분한 임베딩 공간을 확보하지 못해 다른 이미지간에도 
유사도가 높게 측정될 수 있기 때문입니다. 반면 앵귤러 마진 거리 같은 경우에는 임베딩 공간을 효율적으로 사용할 수 있어 더 효과적인것으로 알려져 있습니다.
이러한 방법으로 AI모델을 구현하였고 최종적으로는 장고 Rest API를 통해 안면 인식 서버를 구현했습니다.

슬라이드 24

이어서 클라우드는 전체 서비스 아키텍쳐를 구성한 후
전송되는 데이터의 형태를 알 수 있도록 데이터베이스를 설계를 진행했습니다 
그 후 백앤드 서버에서 장고와 장고레스트프레임워크 라이브러리를 이용하여 Restful API를 만들었고 리액트에서는 해당 API 를 사용해 메뉴 목록이 보이도록 설계하였습니다. 
장고서버는 ec2에서 가동중이며 nohup 명령어로 실행하여 백그라운드에서도 서버가 가동될 수 있도록 해주었습니다.
리액트 서버는 s3 버킷에 업로드하여 배포를 진행하였습니다.

슬라이드25
다음은 저희 주문페이지에 대해 설명드리겠습니다. 
앞에서 설명드린 앱에서 주문하기 버튼을 누르면, 이처럼 첫페이지로 추천메뉴판이 노출됩니다. 
추천메뉴판은 빅데이터분석으로 선별한 데이터이며 상단에 보시면 메인, 사이드, 음료, 추가 메뉴판으로 각각 구성돼있습니다. 
담기전 카트는 이런 상태이며, 메뉴를 담으면 이렇게 카트로 들어옵니다. 카트에서는 + - 버튼으로 수량을 조절할 수 있고 checkout을 누르면 고객아이디와 주문내역이 데이터베이스 서버로 보내져 다음 추천 분석 데이터로 이용됩니다.

